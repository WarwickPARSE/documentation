\section{Background Subtraction and Person Isolation}
\label{background subtraction and person isolation}
In order to create a point cloud of a person, the tool kit must be able to isolate the person being scanned from the background environment. This is a well researched problem and is an issue for many applications in the computer vision field. Background subtraction is a commonly used class of techniques for segmenting out objects of interest in a scene for applications such as surveillance \cite{McIvor2000}. Even though many background subtraction algorithms have been proposed in the literature, the problem of identifying moving objects in complex environment is still far from being completely solved \cite{Cheung2007}.\\

There are many algorithms for isolating objects and relatively few, to no, algorithms specifically designed to isolate only a person. Therefore, research focused on generic isolation algorithms any person isolation algorithm must share some similarities with generic object isolation algorithms. These similarities between the algorithms for object isolation and person isolation are that both must \cite{Cheung2007}:\begin{itemize}
  \item Be robust against changes in illumination
  \item Avoid detecting non-stationary background objects such as swinging leaves
  \item React quickly to changes
\end{itemize}

\subsection{General Approaches, Properties and Steps}
A common approach for isolating general objects is to perform background subtraction, which identifies moving objects from the portion of a video frame that differs significantly from a background model \cite{Cheung2007}.\\

Approaches to object isolation vary from simple techniques such as frame differencing and adaptive median filtering, to more sophisticated probabilistic modelling techniques. 
While complicated techniques often produce superior performance, experiments \cite{Cheung2007} show that simple techniques such as adaptive median filtering can produce good results with much lower computational complexity.\\

In general, the four major steps in a background subtraction algorithm are preprocessing, background modelling, foreground detection, and data validation.
Preprocessing consists of a collection of simple image processing tasks that change the raw input video into a format that can be processed by subsequent steps and can involve noise reduction and frame size/rate reductions \cite{Cheung2007}\\.

Background modelling uses the new video frame to calculate and update a background model.
This background model provides a statistical description of the entire background scene and can be non-recursive or recursive. 
A non-recursive technique uses a sliding-window approach for background estimation. 
The technique stores a buffer of the previous $L$ video frames, and estimates the background image based on the temporal variation of each pixel within the buffer.
Non-recursive techniques are highly adaptive as they do not depend on the history beyond those frames stored in the buffer \cite{Cheung2007}, which may make the ideal for the tool kit.
On the other hand, the storage requirement can be significant if a large buffer
is needed to cope with slow-moving objects \cite{Cheung2007}, although that should not be a problem for the tool kit. Recursive techniques do not use a buffer but maintain a single background model based on each input frame. As a result, input frames from distant past could have an effect on the current background model \cite{Cheung2007} and hence may not be suitable for the tool kit.\\

Foreground detection then identifies pixels in the video frame that cannot be adequately explained by the background model and outputs them as a binary candidate foreground mask. 
Data validation examines the candidate mask and attempt to reduce false-positive or false-negative regions and eliminates those pixels that do not correspond to actual moving objects, and outputs the final foreground mask \cite{Cheung2007}.\\

\subsection{Specific Algorithms}
\label{person_isolation:specific algorithms}
This section will give an overview of several background isolation algorithms and details their running time complexity and accuracy. Two studies were looked at to determine the effectiveness of each method. Piccardi's study \cite{Piccardi2004} focused on the methods Mixture of Gaussian (MOG), Running Gaussian Average (RGA), Temporal Median Filtering (TMF), Kernel Density Estimation (KDE), Sequential Kernel Density Approximation (SDKA), Cooccurence of Image Variations (CIV) and Eigenbackgrounds (EB) whilst Cheung's \cite{Cheung2007} focused on Frame Differencing (FD), Approximate Median Filtering (AMF), Kalman Filtering (KF), MOG again and Median Filtering (MF) \\

\subsubsection{Mixture of Gaussian}
The MOG method \cite{Stauffer1999} has $O(m)$ complexity, where $m$ is the number of Gaussian distributions used, typically 3 to 5. MOG has a high accuracy \cite{Piccardi2004}. In Cheung's experiments \cite{Cheung2007}, MOG performed the best.\\

\subsubsection{Running Gaussian Average}
The fastest amongst the methods reviewed by Piccardi was the RGA method \cite{Wren1997,Koller1994}, having a time complexity of $O(1)$. RGA is a real-time system for tracking people and interpreting their behaviour. It runs at 10Hz on a standard computer, and has performed reliably on thousands of people in many
different physical locations \cite{Wren1997}. RGA has a low/medium accuracy \cite{Piccardi2004}.\\

\subsubsection{Temporal Median Filtering}
TMF \cite{Lo2001,Cucchiara2003} has a similar classification cost to RGA, but updating the  model is approximated as linear in the number of samples, $n$, therefore the corresponding complexity is consider $O(n)$. TMF also has a similar accuracy to RGA, low/medium \cite{Piccardi2004}.\\

\subsubsection{Kernel Density Estimation}
The KDE \cite{Elgammal2000} model computes its value in the Gaussian kernels centred on the past $n$ frames, thus the complexity is $O(n)$, where $n$ is typically as high as 100. However, efficient implementation through the Fast Gauss transform can limit the actual execution time \cite{Elgammal2003}. KDE has a high accuracy \cite{Piccardi2004}.\\

\subsubsection{Sequential Kernel Density approximation}
The SKDA \cite{Han2004} method has $O(m)$ complexity, where $m$ is the number of modes of the approximated posterior density function. The precise number depends on the actual data samples, however this number has been shown to vary between 3 and 11 for video \cite{Han2007}. SDKA has a medium/high accuracy \cite{Piccardi2004}.

\subsubsection{Cooccurence of image variations}
The complexity for the CIV \cite{Seki2003} method has been
estimated as $O(8*(n+L^4+L)/n^2)$, where $n$ is accounted for searching the nearest neighbours amongst the $n$ variations, $L^4$ is the estimated cost for computing the interpolation coefficients and L is the cost of applying them to the current block. CIV has a medium accuracy \cite{Piccardi2004}.\\

\subsubsection{Eigenbackgrounds}
The EB method \cite{Oliver2000} has an estimated complexity per pixel of $O(m)$, where $m$ is the number of the best eigenvectors. EB has a medium accuracy \cite{Piccardi2004}.\\

\subsubsection{Frame Differencing}
Arguably the simplest background modelling technique, FD uses the video frame at time $t_1$ as the background model for the frame at time $t$. Since it uses only
a single previous frame, FD may not be able to identify the interior pixels of a large, uniformly-coloured moving object \cite{Cheung2007}. This is commonly known as the aperture problem and may be a problem as people may wear single coloured clothing. FD was significantly worse than all the other schemes in Cheung's experiments \cite{Cheung2007}.

\subsubsection{Approximate Median Filtering} 
Even though AMF performed worse than MoG and MF, it produced a good performance with an extremely simple implementation. The only drawback of AMF was that it adapts slowly toward a large change in background \cite{Cheung2007}. However this is not expected to be a problem for the tool kit as the should not be any large changes in the background of a doctor's office.\\

\subsubsection{Kalman Filtering}
Visually, KF produced the worst foreground masks among all the schemes. Even with a large foreground threshold and slow adapting rates. As a result, it typically left a long trail after a moving object \cite{Cheung2007}. Slow updating may be an issue if the  person is required to move at all during the scan.\\

\subsubsection{Median Filtering}
Median Filtering is one of the most commonly-used background modelling techniques. The background estimate is defined to be the median at each pixel location of all the frames in the buffer. The assumption is that the pixel stays in the background for more than half of the frames in the buffer \cite{Cheung2007}. Median Filtering has been extended to color by replacing the median with the medoid \cite{Cucchiara2003}. The time complexity of computing the median is $O(L*log(L))$ for each pixel. MF was a very close second in Cheung's experiments .

\subsection{Which method is best?}
The experiments above \cite{Cheung2007,Piccardi2004} suggest that, at this early stage, MOG and KDE, as its accuracy depends on buffer size, may be of use as they are highly accurate and take linear time.\\